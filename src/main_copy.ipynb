{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT 2 \n",
    "(Natural Language Processing)\n",
    "### AUTHORS\n",
    "[UJJWAL KUMAR : 260730680]\n",
    "\n",
    "[ABDULLAHI ELMI : 260727124]\n",
    "\n",
    "[FURAHA DAMIEN : 260754407]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "from sklearn import datasets\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classes = ['comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware',\n",
    "           'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos',\n",
    "           'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'talk.politics.misc',\n",
    "           'talk.politics.guns', 'talk.politics.mideast', 'sci.crypt', 'sci.electronics',\n",
    "           'sci.med', 'sci.space', 'talk.religion.misc', 'alt.atheism', 'soc.religion.christian']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOADING DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".... Loading training DATASET..... \n",
      ".....Done......\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# twenty_test = None\n",
    "# twenty_train = None\n",
    "# docs_test = None\n",
    "# '''\n",
    "# NOT FOR .ipynb files\n",
    "#  Ask user for which data set they wanna test'''\n",
    "# dataset_name =sys.argv[1]\n",
    "# print(\"You choose dataset : \", sys.argv)\n",
    "# if(dataset_name == \"imdb\"):\n",
    "#     #  Training set for IMDB datasets\n",
    "#     twenty_train = datasets.load_files(\"../dataset/data/train\", description=None, categories=None,\n",
    "#                                        load_content=True, shuffle=True, encoding='utf-8', decode_error='strict', random_state=0)\n",
    "#     #  IMDB test dataset\n",
    "#     twenty_test = datasets.load_files(\"../dataset/data/test\", description=None, categories=None,\n",
    "#                                       load_content=True, shuffle=True, encoding='utf-8', decode_error='strict', random_state=0)\n",
    "#     docs_test = twenty_test.data\n",
    "# else:\n",
    "#     # Training set for 20 news groups dataset\n",
    "#     twenty_train = fetch_20newsgroups(\n",
    "#         subset='train', categories=classes, shuffle=True, random_state=42)\n",
    "#     # TEST SET for 20 new group\n",
    "#     twenty_test = fetch_20newsgroups(\n",
    "#         subset='test', categories=classes, shuffle=True, random_state=42)\n",
    "#     docs_test = twenty_test.data\n",
    "\n",
    "\n",
    "# load data\n",
    "path = os.getcwd()\n",
    "print(\".... Loading training DATASET..... \")\n",
    "print(\".....Done......\")\n",
    "''' Training set for IMDB datasets'''\n",
    "#twenty_train = datasets.load_files(\"../dataset/data/train\", description=None, categories=None,\n",
    "#                                   load_content=True, shuffle=True, encoding='utf-8', decode_error='strict', random_state=0)\n",
    "\n",
    "''' Training set for 20 news groups dataset '''\n",
    "twenty_train = fetch_20newsgroups(\n",
    "     subset='train', categories=classes, shuffle=True, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT PROCESSING PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating text processing pipline... \n",
      "(11314, 130107)\n",
      ".... Loading testing DATASET..... \n",
      ".....Done......\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "PRE-PROCESSING\n",
    "    constructing bag of words\n",
    "    tokenizing and filtering of stopwords\n",
    "    feature extraction\n",
    "    counts of N-grams of words\n",
    "    downscale word weights by frequency\n",
    "\"\"\"\n",
    "# creating pipeline\n",
    "\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\n",
    "\n",
    "\n",
    "print(\"Creating text processing pipline... \")\n",
    "\n",
    "def PIPELINE(classifier):\n",
    "    pipeline_1 = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', classifier)\n",
    "                           ])\n",
    "    pipeline_2 = Pipeline([('vect', CountVectorizer(tokenizer=LemmaTokenizer(),\n",
    "                                                    strip_accents='unicode',  # works\n",
    "                                                    stop_words='english',  # works\n",
    "                                                    lowercase=True,)), ('tfidf', TfidfTransformer()), ('clf', classifier)\n",
    "                           ])\n",
    "    return pipeline_1\n",
    "\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "\n",
    "print(\".... Loading testing DATASET..... \")\n",
    "print(\".....Done......\")\n",
    "# TEST SET\n",
    "twenty_test = fetch_20newsgroups(subset='test',\n",
    "                                  categories=classes, shuffle=True, random_state=42)\n",
    "\n",
    "#''' IMDB test dataset'''\n",
    "#twenty_test = datasets.load_files(\"../dataset/data/test\", description=None, categories=None,\n",
    "#                                  load_content=True, shuffle=True, encoding='utf-8', decode_error='strict', random_state=0)\n",
    "docs_test = twenty_test.data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== LOGISTIC REGRESSION =======================\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.82      0.78      0.80       319\n",
      "           comp.graphics       0.75      0.80      0.78       389\n",
      " comp.os.ms-windows.misc       0.77      0.73      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.70      0.74      0.72       392\n",
      "   comp.sys.mac.hardware       0.83      0.85      0.84       385\n",
      "          comp.windows.x       0.85      0.76      0.80       395\n",
      "            misc.forsale       0.82      0.90      0.86       390\n",
      "               rec.autos       0.92      0.90      0.91       396\n",
      "         rec.motorcycles       0.96      0.96      0.96       398\n",
      "      rec.sport.baseball       0.92      0.94      0.93       397\n",
      "        rec.sport.hockey       0.96      0.98      0.97       399\n",
      "               sci.crypt       0.94      0.93      0.94       396\n",
      "         sci.electronics       0.79      0.80      0.79       393\n",
      "                 sci.med       0.90      0.86      0.88       396\n",
      "               sci.space       0.90      0.93      0.92       394\n",
      "  soc.religion.christian       0.84      0.93      0.89       398\n",
      "      talk.politics.guns       0.75      0.91      0.83       364\n",
      "   talk.politics.mideast       0.97      0.90      0.93       376\n",
      "      talk.politics.misc       0.81      0.62      0.70       310\n",
      "      talk.religion.misc       0.75      0.64      0.69       251\n",
      "\n",
      "                accuracy                           0.85      7532\n",
      "               macro avg       0.85      0.84      0.84      7532\n",
      "            weighted avg       0.85      0.85      0.85      7532\n",
      "\n",
      "Raw accurracy = 85.077%\n"
     ]
    }
   ],
   "source": [
    "# TRAIN CLASSIFIERS\n",
    "# =====================LOGISTIC REGRESSION========================\n",
    "print(\"================== LOGISTIC REGRESSION =======================\")\n",
    "classifier = LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
    "                                intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                                multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                                random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
    "                                warm_start=False)\n",
    "# pipeline = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', classifier)\n",
    "#                      ])\n",
    "pipeline = PIPELINE(classifier)\n",
    "\n",
    "pipeline.fit(twenty_train.data, twenty_train.target)\n",
    "predicted = pipeline.predict(docs_test)\n",
    "\n",
    "''' Classification for 20 news group dataset'''\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "                                     target_names=twenty_test.target_names))\n",
    "#'''Classification report for IMDB dataset '''\n",
    "#print(metrics.classification_report(twenty_test.target, predicted))\n",
    "\n",
    "# print(metrics.confusion_matrix(twenty_test.target, predicted))\n",
    "print(\"Raw accurracy = %.3f%%\" %\n",
    "      ((np.mean(predicted == twenty_test.target))*100.0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRID SEARCH\n",
    "(LOGISTIC REGRESSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< REPORT >>\n",
      "Best score accurracy = 92.425%\n",
      "Best parameters are:\n",
      "{'clf__C': 1000, 'clf__max_iter': 7600, 'clf__tol': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression parameter tuning with GridSearchCV\n",
    "# TODO: Add more hyperparameter tuning\n",
    "# pipeline = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', LogisticRegression())\n",
    "#                      ])\n",
    "# regularization hyperparameter space\n",
    "\n",
    "hyperparameters = {\n",
    "    'clf__C': [0.1, 1, 100, 1000],\n",
    "    # 'clf__penalty': ['l1', 'l2'],\n",
    "    'clf__max_iter': [7600, 1000],\n",
    "    'clf__tol': [0.00001, 0.0001, 0.005]\n",
    "}\n",
    "grid_logistic = GridSearchCV(pipeline, hyperparameters, cv=5, )\n",
    "\n",
    "clf_best = grid_logistic.fit(twenty_train.data, twenty_train.target)\n",
    "print(\"<< REPORT >>\")\n",
    "print(\"Best score accurracy = %.3f%%\" % ((clf_best.best_score_)*100.0))\n",
    "print(\"Best parameters are:\")\n",
    "print(clf_best.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DECISION TREES =======================\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.47      0.48      0.48       319\n",
      "           comp.graphics       0.43      0.43      0.43       389\n",
      " comp.os.ms-windows.misc       0.52      0.57      0.54       394\n",
      "comp.sys.ibm.pc.hardware       0.47      0.39      0.43       392\n",
      "   comp.sys.mac.hardware       0.54      0.58      0.56       385\n",
      "          comp.windows.x       0.49      0.48      0.48       395\n",
      "            misc.forsale       0.66      0.73      0.69       390\n",
      "               rec.autos       0.64      0.59      0.62       396\n",
      "         rec.motorcycles       0.71      0.77      0.74       398\n",
      "      rec.sport.baseball       0.55      0.55      0.55       397\n",
      "        rec.sport.hockey       0.66      0.66      0.66       399\n",
      "               sci.crypt       0.76      0.69      0.72       396\n",
      "         sci.electronics       0.34      0.34      0.34       393\n",
      "                 sci.med       0.49      0.42      0.45       396\n",
      "               sci.space       0.61      0.65      0.63       394\n",
      "  soc.religion.christian       0.68      0.73      0.70       398\n",
      "      talk.politics.guns       0.49      0.62      0.55       364\n",
      "   talk.politics.mideast       0.81      0.59      0.68       376\n",
      "      talk.politics.misc       0.41      0.40      0.40       310\n",
      "      talk.religion.misc       0.32      0.31      0.31       251\n",
      "\n",
      "                accuracy                           0.56      7532\n",
      "               macro avg       0.55      0.55      0.55      7532\n",
      "            weighted avg       0.56      0.56      0.56      7532\n",
      "\n",
      "raw accurracy = 55.616%\n",
      "[0.6122807  0.64674868 0.62917399 0.63556338 0.64134276 0.64747564\n",
      " 0.61702128 0.65541741 0.63078292 0.65449688]\n"
     ]
    }
   ],
   "source": [
    "# ===================== DECISION TREES ========================\n",
    "print(\"================== DECISION TREES =======================\")\n",
    "clf_decision_trees = DecisionTreeClassifier(random_state=0)\n",
    "# pipeline = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', clf_decision_trees)\n",
    "#  ])\n",
    "pipeline = PIPELINE(clf_decision_trees)\n",
    "pipeline.fit(twenty_train.data, twenty_train.target)\n",
    "predicted = pipeline.predict(docs_test)\n",
    "\n",
    "\n",
    "''' Classification for 20 news group dataset'''\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "                                     target_names=twenty_test.target_names))\n",
    "#'''Classification report for IMDB dataset '''\n",
    "#print(metrics.classification_report(twenty_test.target, predicted))\n",
    "# print(metrics.confusion_matrix(twenty_test.target, predicted))\n",
    "\n",
    "\n",
    "print(\"raw accurracy = %.3f%%\" %\n",
    "      ((np.mean(predicted == twenty_test.target))*100.0))\n",
    "print(cross_val_score(pipeline, twenty_train.data, twenty_train.target, cv=10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRID SEARCH\n",
    "(DECISION TREES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< REPORT >>\n",
      "Best score accurracy = 42.151%\n",
      "Best parameters are:\n",
      "{'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__max_features': 'auto', 'clf__splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "# Decision trees parameter tuning with GridSearchCV\n",
    "# pipeline = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', DecisionTreeClassifier())\n",
    "#                      ])\n",
    "hyperparameters = {\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "    'clf__splitter': ['best', 'random'],\n",
    "    'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'clf__class_weight': ['balanced']\n",
    "}\n",
    "grid_d_trees = GridSearchCV(pipeline, hyperparameters, cv=5)\n",
    "clf_best = grid_d_trees.fit(\n",
    "    twenty_train.data, twenty_train.target)\n",
    "print(\"<< REPORT >>\")\n",
    "print(\"Best score accurracy = %.3f%%\" % ((clf_best.best_score_)*100.0))\n",
    "print(\"Best parameters are:\")\n",
    "print(clf_best.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== SUPPORT VECTOR MACHINE =======================\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.82      0.79      0.81       319\n",
      "           comp.graphics       0.78      0.79      0.78       389\n",
      " comp.os.ms-windows.misc       0.75      0.73      0.74       394\n",
      "comp.sys.ibm.pc.hardware       0.73      0.76      0.74       392\n",
      "   comp.sys.mac.hardware       0.84      0.85      0.85       385\n",
      "          comp.windows.x       0.87      0.76      0.81       395\n",
      "            misc.forsale       0.84      0.92      0.87       390\n",
      "               rec.autos       0.93      0.90      0.91       396\n",
      "         rec.motorcycles       0.94      0.95      0.95       398\n",
      "      rec.sport.baseball       0.92      0.96      0.94       397\n",
      "        rec.sport.hockey       0.96      0.98      0.97       399\n",
      "               sci.crypt       0.92      0.94      0.93       396\n",
      "         sci.electronics       0.82      0.79      0.80       393\n",
      "                 sci.med       0.90      0.88      0.89       396\n",
      "               sci.space       0.90      0.94      0.92       394\n",
      "  soc.religion.christian       0.84      0.94      0.88       398\n",
      "      talk.politics.guns       0.74      0.92      0.82       364\n",
      "   talk.politics.mideast       0.96      0.90      0.93       376\n",
      "      talk.politics.misc       0.85      0.62      0.72       310\n",
      "      talk.religion.misc       0.73      0.60      0.66       251\n",
      "\n",
      "                accuracy                           0.85      7532\n",
      "               macro avg       0.85      0.85      0.85      7532\n",
      "            weighted avg       0.85      0.85      0.85      7532\n",
      "\n",
      "raw accurracy = 85.422%\n"
     ]
    }
   ],
   "source": [
    "# =====================SVM - LINEARSVC ========================\n",
    "print(\"================== SUPPORT VECTOR MACHINE =======================\")\n",
    "classifier = LinearSVC(loss='hinge', penalty='l2',\n",
    "                       random_state=0, max_iter=76000, tol=1e-5)\n",
    "# clf = Pipeline([\n",
    "#     ('vect', CountVectorizer()),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('clf', LinearSVC(loss='hinge', penalty='l2',\n",
    "#                       random_state=0, max_iter=76000, tol=1e-5)),\n",
    "# ])\n",
    "clf = PIPELINE(classifier)\n",
    "clf.fit(twenty_train.data, twenty_train.target)\n",
    "predicted = clf.predict(docs_test)\n",
    "\n",
    "\n",
    "''' Classification for 20 news group dataset'''\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "                                     target_names=twenty_test.target_names))\n",
    "#'''Classfication report for IMDB dataset  '''\n",
    "#print(metrics.classification_report(twenty_test.target, predicted))\n",
    "\n",
    "# print(metrics.confusion_matrix(twenty_test.target, predicted))\n",
    "\n",
    "\n",
    "print(\"raw accurracy = %.3f%%\" %\n",
    "      ((np.mean(predicted == twenty_test.target))*100.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRID SEARCH\n",
    "(SUPPORT VECTOR MACHINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< REPORT >>\n",
      "Best score accurracy = 92.363%\n",
      "Best parameters are : \n",
      "{'clf__max_iter': 7600, 'clf__tol': 0.0001, 'tfidf__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC parameter tuning with GridSearchCV\n",
    "# clf=Pipeline([\n",
    "#     ('vect', CountVectorizer()),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('clf', LinearSVC())\n",
    "# ])\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__tol': [1e-2, 1e-4, 1e-9],\n",
    "    'clf__max_iter': [7600, 1000]\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, cv=5, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "print(\"<< REPORT >>\")\n",
    "print(\"Best score accurracy = %.3f%%\" % ((gs_clf.best_score_)*100.0))\n",
    "print(\"Best parameters are : \")\n",
    "print(gs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADABOOST CLASSIFIER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== ADABOOST CLASSIFIER =======================\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.64      0.30      0.41       319\n",
      "           comp.graphics       0.50      0.24      0.33       389\n",
      " comp.os.ms-windows.misc       0.63      0.48      0.54       394\n",
      "comp.sys.ibm.pc.hardware       0.20      0.46      0.28       392\n",
      "   comp.sys.mac.hardware       0.57      0.56      0.56       385\n",
      "          comp.windows.x       0.72      0.41      0.52       395\n",
      "            misc.forsale       0.80      0.70      0.75       390\n",
      "               rec.autos       0.77      0.55      0.64       396\n",
      "         rec.motorcycles       0.83      0.76      0.79       398\n",
      "      rec.sport.baseball       0.59      0.59      0.59       397\n",
      "        rec.sport.hockey       0.89      0.58      0.70       399\n",
      "               sci.crypt       0.84      0.71      0.77       396\n",
      "         sci.electronics       0.14      0.43      0.21       393\n",
      "                 sci.med       0.65      0.28      0.39       396\n",
      "               sci.space       0.68      0.54      0.61       394\n",
      "  soc.religion.christian       0.70      0.71      0.71       398\n",
      "      talk.politics.guns       0.56      0.59      0.58       364\n",
      "   talk.politics.mideast       0.81      0.59      0.68       376\n",
      "      talk.politics.misc       0.39      0.37      0.38       310\n",
      "      talk.religion.misc       0.29      0.38      0.33       251\n",
      "\n",
      "                accuracy                           0.52      7532\n",
      "               macro avg       0.61      0.51      0.54      7532\n",
      "            weighted avg       0.62      0.52      0.55      7532\n",
      "\n",
      "raw accurracy = 51.845%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================ADABOOST CLASSIFIER========================\n",
    "print(\"================== ADABOOST CLASSIFIER =======================\")\n",
    "classifier = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "# clf_adaboost = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', AdaBoostClassifier(n_estimators=100, random_state=0))\n",
    "#                          ])\n",
    "clf_adaboost = PIPELINE(classifier)\n",
    "clf_adaboost.fit(twenty_train.data, twenty_train.target)\n",
    "predicted = clf_adaboost.predict(docs_test)\n",
    "\n",
    "\n",
    "''' Classification for 20 news group dataset'''\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "                                     target_names=twenty_test.target_names))\n",
    "\n",
    "'''Classification for IMDB dataset '''\n",
    "#print(metrics.classification_report(twenty_test.target, predicted))\n",
    "\n",
    "# print(metrics.confusion_matrix(twenty_test.target, predicted))\n",
    "\n",
    "\n",
    "print(\"raw accurracy = %.3f%%\" %\n",
    "      ((np.mean(predicted == twenty_test.target))*100.0))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRID SEARCH\n",
    "(ADABOOST CLASSIFIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< REPORT >>\n",
      "Best score accurracy = 53.376%\n",
      "Best parameters are : \n",
      "{'clf__learning_rate': 0.3, 'clf__n_estimators': 70}\n"
     ]
    }
   ],
   "source": [
    "# AdaBoostClassifier parameter tuning with GridSearchCV\n",
    "# clf = Pipeline([\n",
    "#     ('vect', CountVectorizer()),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('clf', AdaBoostClassifier())\n",
    "# ])\n",
    "\n",
    "parameters = {\n",
    "    'clf__n_estimators': [20, 50, 70, 100],\n",
    "    'clf__learning_rate': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\n",
    "gs_clf = GridSearchCV(clf_adaboost, parameters, cv=kfold, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "print(\"<< REPORT >>\")\n",
    "print(\"Best score accurracy = %.3f%%\" % ((gs_clf.best_score_)*100.0))\n",
    "print(\"Best parameters are : \")\n",
    "print(gs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== RANDOM FOREST =======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.40      0.11      0.17       319\n",
      "           comp.graphics       0.74      0.14      0.23       389\n",
      " comp.os.ms-windows.misc       0.08      0.71      0.14       394\n",
      "comp.sys.ibm.pc.hardware       0.85      0.06      0.11       392\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
      "          comp.windows.x       0.89      0.13      0.23       395\n",
      "            misc.forsale       1.00      0.01      0.01       390\n",
      "               rec.autos       0.00      0.00      0.00       396\n",
      "         rec.motorcycles       0.00      0.00      0.00       398\n",
      "      rec.sport.baseball       0.20      0.05      0.08       397\n",
      "        rec.sport.hockey       0.47      0.09      0.15       399\n",
      "               sci.crypt       0.13      0.12      0.12       396\n",
      "         sci.electronics       0.00      0.00      0.00       393\n",
      "                 sci.med       0.08      0.35      0.12       396\n",
      "               sci.space       1.00      0.15      0.26       394\n",
      "  soc.religion.christian       0.21      0.29      0.25       398\n",
      "      talk.politics.guns       0.46      0.48      0.47       364\n",
      "   talk.politics.mideast       0.44      0.44      0.44       376\n",
      "      talk.politics.misc       0.00      0.00      0.00       310\n",
      "      talk.religion.misc       0.00      0.00      0.00       251\n",
      "\n",
      "                accuracy                           0.16      7532\n",
      "               macro avg       0.35      0.16      0.14      7532\n",
      "            weighted avg       0.36      0.16      0.14      7532\n",
      "\n",
      "raw accurracy = 15.985%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================RANDOM FOREST========================\n",
    "print(\"================== RANDOM FOREST =======================\")\n",
    "\n",
    "classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "# clf_random_forest = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', RandomForestClassifier(max_depth=2, random_state=0))\n",
    "# ])\n",
    "clf_random_forest = PIPELINE(classifier)\n",
    "clf_random_forest.fit(twenty_train.data, twenty_train.target)\n",
    "predicted = clf_random_forest.predict(docs_test)\n",
    "\n",
    "\n",
    "# ======= meteric classification\n",
    "''' Classification for 20 news group dataset'''\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "                                     target_names=twenty_test.target_names))\n",
    "\n",
    "#'''Classification for IMDB dataset '''\n",
    "#print(metrics.classification_report(twenty_test.target, predicted))\n",
    "# print(metrics.confusion_matrix(twenty_test.target, predicted))\n",
    "\n",
    "\n",
    "print(\"raw accurracy = %.3f%%\" %\n",
    "      ((np.mean(predicted == twenty_test.target))*100.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRID SEARCH\n",
    "(RANDOM FOREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< REPORT >>\n",
      "Best score accurracy = 74.147%\n",
      "best parameters are: \n",
      "{'clf__criterion': 'gini', 'clf__max_depth': 8, 'clf__max_features': 'auto', 'clf__n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# AdaBoostClassifier parameter tuning with GridSearchCV\n",
    "# clf_random_forest=Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', RandomForestClassifier())\n",
    "#                               ])\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [200, 500],\n",
    "    'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'clf__max_depth': [4, 5, 6, 7, 8],\n",
    "    'clf__criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_random_forest = GridSearchCV(\n",
    "    clf_random_forest, param_grid, cv=5, n_jobs=-1)\n",
    "grid_random_forest.fit(twenty_train.data, twenty_train.target)\n",
    "predicted = grid_random_forest.predict(docs_test)\n",
    "\n",
    "print(\"<< REPORT >>\")\n",
    "print(\"Best score accurracy = %.3f%%\" %\n",
    "      ((grid_random_forest.best_score_)*100.0))\n",
    "print(\"best parameters are: \")\n",
    "print(grid_random_forest.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
